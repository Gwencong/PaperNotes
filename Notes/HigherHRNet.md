# HigherHRNet阅读笔记

**[Higherhrnet: Scale-aware representation learning for bottom-up human pose estimation](https://openaccess.thecvf.com/content_CVPR_2020/papers/Cheng_HigherHRNet_Scale-Aware_Representation_Learning_for_Bottom-Up_Human_Pose_Estimation_CVPR_2020_paper.pdf)**

## Abstract

​		提出了一种自底向上的姿态估计模型（之前的HRNet是自顶向下的模型），为了解决尺度变化的问题，作者引入了转置卷积模块来提高特征图的分辨率，形成特征金字塔，同时融合多尺度的高分辨率特征来进行姿态估计，达到SOTA

## 1. Introduction

​		自底向上的方法存在的主要挑战是对于小目标的姿态难以估计，主要在于两个方面：一是人的尺寸变化问题，需要在提高小目标的姿态估计准确性的同时不牺牲对于大目标检测的准确性；二是如何产生对于小目标而言的具有高质量的精确位置信息的高分辨率热图。传统的特征金字塔从1/32分辨率开始，使用横向连接的双线性上采样，将特征图分辨率逐渐提高到1/4。

​		HigherHRNet的高分辨率特征金字塔直接从1/4分辨率（backbone中最高分辨率的特征）开始，并通过转置卷积生成更高分辨率的特征图。为了使HigherHRNet高效，作者在HRNet的1/4分辨率路径上构建了高分辨率的特征金字塔；为了使HigherHRNet能够处理目标规模的变化，作者进一步提出了一种多分辨率监督策略，将不同分辨率的训练目标分配到相应级别的特征金字塔。最后，在推理过程中引入了一种简单的多分辨率热图聚合策略来生成具有尺度感知能力的高分辨率热图。

​		作者实验观察到HigherHRNet的主要提高来源于数据集中对于中等尺度目标的检测的提高（因为在COCO中没有小尺度的目标）

​		论文的主贡献可以总结为以下几点：

* 尝试解决在之的自底向上的方法中很少研究的目标尺度变化问题
* 提出了能够生成多尺度的高分辨特征金字塔的HigherHRNet，在训练阶段使用多分辨率监督，在推理阶段使用多分辨率热图聚合，从而使HigherHRNet能够具有尺度感知能力，对于小目标的姿态估计是有益的。
* 证明了HigherHRNet的有效性，在颇具挑战性的COCO数据集上到达SOTA，特别是在中等尺度的目标上的准确性具有很大的提高。
* 在拥挤场景姿态估计数据集CrowdPose上也达到SOTA，说明自底向上的方法在拥挤的场景下比自顶向下的方法更加鲁棒。

## 2. Related works

​		这部分简要介绍了一些自底向上的方法和一些自顶向下的方法，以及特征金字塔方法 。

## 3. Higher-Resolution Network

### 3.1 HigherHRNet

​		HigherHRNet实际上就是在HRNet的bottom-up版本，在HRNet的基础上加入转置卷积，使得网络能够得到更高分辨率的特征，能偶更好的检测小目标的姿态，其结构如图所示。

![avatar](https://github.com/Gwencong/PaperNotes/blob/main/imgs/higherhrnet.png)

<center>图1 HigherHRNet的结构图</center>

​		热图的分辨率对于预测小人物的关键点很重要。大多数现有的人体姿态估计方法都是预测高斯平滑的关键点热图，对应的ground truth热图通过对ground truth中的每个关键点位置用一个非标准化的高斯核进行处理得到。添加这个高斯核有助于训练网络，因为cnn倾向于输出作为卷积操作的一种性质的空间平滑的响应。然而，应用高斯核也会导致关键点的精确定位的混淆，特别是对于属于图片占比小的人的关键点的预测（**这里我的理解是因为小目标区域小，因此在这个区域预测的热图就会普遍热度较大，难以确定每个关节的具体位置**），一种简单的解决方案就是减小高斯核的标准差，这样会使得高斯核在分布上变窄，从而缩小每个关键点附近的高热度区域，使得热图上关键点之间能够被明显分开，但是作者经验性的认为这样做会使得网络的训练变得困难甚至导致更加糟糕的结果。

​		作者采取的解决方案就是增加图片的分辨率，使得小目标也能被估计出来，并且使用能够产生高质量特征图的转置卷积来进行上采样。

### 3.2 Grouping

​		有研究表明使用associative embedding能够以较高的准确率解决关键点分组问题，因此作者采用了这种方法，分组过程为将tag具有较小L2距离的关键点分组，最后使得关键点形成个体。

### 3.3  Deconvolution Module

使用转置卷积作为deconvolution模块，可选择性的在转置卷积后使用几个残差模块来提炼特征信息，每个转置卷积模块的输出特征图也被用于预测多尺度的热图。

### 3.4 Multi-Resolution Supervision

​		不同于一般的只对最高分辨率热图计算loss的方法，作者采取多分辨率的监督，对于每个分辨率的热图都用同一个高斯核产生对应级别的label，然后对每个级别的热图都进行loss的计算，总的loss是所有loss的和，loss采用MSE。之所以对不同级别的热图使用同一个高斯核是因为作者认为不同分辨率的特征图适用于不同尺度的关键点，因此无需对特征图使用不同标准差的高斯核，使用同样标准差的高斯核即可。而在更高分辨率的特征图上，需要一个相对较小的标准差（与特征图的分辨率相比）来更精确地定位占比小的人物的关键点。

​		值得注意的是，作者并没有将不同规模的人分配到特征金字塔中的不同层次。主要是基于以下原因而考虑的： *首先，用于分配训练目标的启发式方法取决于数据集和网络架构， 很难将 FPN 的启发式信息转换为 HigherHRNet，因为数据集（人与所有对象的规模分布）和架构（HigherHRNet 只有 2 层金字塔，而 FPN 有 4 层）都发生了变化。 其次，由于应用了高斯核，ground truth 关键点目标相互交互。* 因此，通过简单地设置忽略区域来解耦关键点是非常困难的。 作者相信模型能够自动关注特征金字塔不同层次的特定尺度。

​		对于tagmap作者只对最低分辨率进行tagmap的预测，因为要学习出tagmap需要进行全局推理，而且预测较低分辨率的tagmap更加合适，因为作者还发现子啊更高的分辨率不能学会很好地预测tagmap，甚至不收敛。因此，在输入图像1/4分辨率的特征图上训练tagmap。

### 3.5 Heatmap Aggregation for Inference

​		对于不同分辨率的热图使用双线性插值进行上采样到与输入图片一样的尺寸，然后将所有的特征图取平均得到最后的预测的热图，使得输出的热图能够感知尺度的变化。

## 4. Experiments

​		作者通过一系列的对比实验和消融实验证明了HigherHRNet的有效性，缩小了与自顶向下方法之间的差距，并且在CrowdPose测试集上比top-down方法有着跟高的表现，说明在拥挤场景下bottom-up的方法往往更合适，同时表民：

* 进行更高分辨率的预测有利于自下而上的姿态估计

* 尺度感知预测是重要的

​        并且作者在设置反卷积模块时只使用了一个转置卷积，多使用时反而会使得表现下降，作者提出一个的猜测：这是因为特征地图尺度和对象尺度之间的错位，更大的分辨率的特征图（特征步幅=1）很适合检测来自尺寸更小的人物的关键点，但COCO中的小尺寸人物不被考虑用于姿态估计。

# 总结

​		论文的主要创新点在于在使用转置卷积进一步提高分辨率，在更高高分辨率上预测热图来解决小尺寸目标姿态估计的问题，同时在这个过程只能进行多尺度特征融合，在训练时采用多分辨率监督，在推理时使用多分辨率聚合，使得网络具有感知目标的多尺度变化问题。